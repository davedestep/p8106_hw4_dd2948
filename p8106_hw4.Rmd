---
title: "Final_TripAdvisor"
author: "David DeStephano"
date: "May 5, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(colorspace)
library(circlize)
library(AppliedPredictiveModeling)
library(ModelMetrics)
library(rpart) #cart
library(rpart.plot)

```

#Introduction
Gaugeing how a potential guest would rate your and other hotels could be a pertinent question within marketing. It could allow you to tailor experiences for a certain guest, suggest additional features/amenities for a higher or lower price that you know the guest would enjoy based on their tripadvisor history. In this exercise, the researchers intend to simply predict guest ratings of a hotel, but this exercise could be extended to a prescriptive analytic framework, in which guest experiences could be tailored based on their tripadvisor accounts. 

This data was precleaned, but multilevel factors were dummified.

There are some issues with this data, weekdays are sometime miscoded as the month. When modeling, the number of rooms is perfectly 1 to 1 with the hotel name, so coefficients are NA automatically. Honestly not exactly sure why this is hosted on UCI's machine learning repository. Having months in the day of week variable is particularly bad.

#Exploratory Analysis
Unfortunately there are few numeric variables about the hotel itself, so the numeric variables we do have show us more about the reviewers, namely, that reviewers that are very active on the site are less likely to leave negative reviews, or vice versa, that non-tripadvisor users are more likely to leave a negative review/people with no reviews will leave a bad review but not a good review. 

Additionally, since scores can only be 1, 2, 3, 4, 5, scatter plots are not particularly useful for visualization. 

#Models
All predictor variables were included. 

Random forest outpeformed the linear model appreciably, and marginally outperformed the decision tree model.

The results for both metrics adopted, MAE, can be seen in the file. In the scale from 1 to 5 used for the score on TripAdvisor, the random forest (the best model) achieved a MAE/average absolute deviation of 0.759. This tells us the model, on average, is within one star of predicting the real score. 






```{r warning=FALSE, message=FALSE}
trip<-read_csv("C:\\Users\\daved\\Documents\\Data Sceince II\\p8106_final_dd2948\\LasVegasTripAdvisorReviews-Dataset.csv") %>% janitor::clean_names() %>% select(-x21)
```



#Exploratory Analysis
```{r}
trip[sapply(trip, is.character)] <- lapply(trip[sapply(trip, is.character)], 
                                       as.factor)


trip<-as.data.frame(trip)

trip2 <- trip[,-14]
```


##Data viz here!!!
```{r}
ggplot(trip, aes(x=traveler_type, y=score)) + 
  geom_violin()


nums<-select_if(trip, is.numeric)


x <-model.matrix(score~.,nums)[,-1]

y <- nums$score

theme1 <-trellis.par.get()
theme1$plot.symbol$col <-rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <-rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <-rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x, y, plot = "scatter", labels =c("","Y"),type =c("p"), layout =c(4, 2))



```

Unfortunately there are few numeric variables about the hotel itself, so the numeric variables we do have show us more about the reviewers, namely, that reviewers that are very active on the site are less likely to leave negative reviews, or vice versa, that non-tripadvisor users are more likely to leave a negative review/people with no reviews will leave a bad review if they had a particularly bad experience.




##First let's try hierarchical clustering to see how hotels cluster together
```{r warning=FALSE, message=FALSE}
d_trip <- dist(trip2) # method="man" # is a bit better
hc_trip <- hclust(d_trip, method = "complete")
trip_hotel <- rev(levels(trip[,14]))



library(dendextend)
dend <- as.dendrogram(hc_trip)

# Color the branches based on the clusters:
dend <- color_branches(dend, k=21) #, groupLabels=trip_hotel)

labels_colors(dend) <-
   rainbow_hcl(21)[sort_levels_values(
      as.numeric(trip[,14])[order.dendrogram(dend)]
   )]

# add the hotel name to the labels:
labels(dend) <- paste(as.character(trip[,14])[order.dendrogram(dend)],
                           "(",labels(dend),")", 
                           sep = "")
dend <- hang.dendrogram(dend,hang_height=0.1)
# reduce the size of the labels:
#dend <- assign_values_to_leaves_nodePar(dend, 0.05, "lab.cex")
dend <- set(dend, "labels_cex", 0.4)
# And plot:
par(mar = c(3,3,3,7))
plot(dend, 
     main = "Clustered trip data set
     (the labels give the true hotel name)", 
     horiz =  TRUE,  nodePar = list(cex = .007))
legend("topleft", legend = trip_hotel, fill = rainbow_hcl(21), cex=0.4)
```


```{r}
par(mar = rep(0,4))
circlize_dendrogram(dend)
```





```{r}
#hc.complete <- hclust(dist(trip), method = "complete")
#hc.average <- hclust(dist(trip), method = "average")
#hc.single <- hclust(dist(trip), method = "single")
#hc.centroid <- hclust(dist(trip), method = "centroid")
```

#Models



##dummify the variables
```{r}
dmy<- dummyVars(" ~.", data=trip, fullRank = T)
trsf <- data.frame(predict(dmy, newdata = trip))

```




##Create test and train datasets
```{r}
set.seed(1)
rowTrain = createDataPartition(trsf$score,
                               p=2/3,
                               list=F)

train <- trsf[rowTrain, ]
test <- trsf[-rowTrain, ]

```


##Linear regression
```{r message=FALSE, warning=FALSE}
ctrl1 <-trainControl(method = "cv", number = 5)
set.seed(1)

lm.fit <-train(score~.,
                data = train,
                method = "lm", 
                trControl = ctrl1)



getTrainPerf(lm.fit)


predy.lm <-predict(lm.fit, newdata = test)



mae(test$score, predy.lm)
mse(test$score, predy.lm)
rmse(test$score, predy.lm)

coef(lm.fit$finalModel) %>% knitr::kable()

```

##Lasso Regression
```{r}
set.seed(1)
lasso.fit <- train(score~., 
                   data=train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-4, 1, length=100))),
                   preProc = c("center", "scale"),
trControl = ctrl1)


ggplot(lasso.fit, highlight = TRUE) + theme_bw()
lasso.fit$bestTune

predy.lasso <-predict(lasso.fit, newdata = test)

mae(test$score, predy.lasso)
mse(test$score, predy.lasso)
rmse(test$score, predy.lasso)

```



##Decision Tree
```{r}
set.seed(1)
tree1 <- rpart(formula = score~., data = train)
rpart.plot(tree1)



set.seed(1)
rpart.fit <-train(score~., train,
                  method = "rpart",
                  tuneGrid =data.frame(cp =exp(seq(-6,-3, length = 20))),
                  trControl = ctrl1)
ggplot(rpart.fit, highlight =TRUE)

rpart.fit$bestTune

rpart.plot(rpart.fit$finalModel)




predy2.rpart <-predict(rpart.fit, newdata = test)
mse(predy2.rpart, test$score)
```

##RF
```{r}
rf.grid <-expand.grid(mtry = 1:12,
                      splitrule = "variance",
                      min.node.size = 1:5)

set.seed(1)

rf.fit <-train(score~., train,
               method = "ranger",
               tuneGrid=rf.grid,
               trControl=ctrl1,
               importance="permutation")

ggplot(rf.fit, highlight = TRUE)
```

```{r}
rfImp <- varImp(rf.fit, scale = FALSE)
rfImp
```


```{r}
predy.rf <-predict(rf.fit, newdata = test)



mae(test$score, predy.rf)
mse(test$score, predy.rf)
rmse(test$score, predy.rf)

```




##SVM/Support Vector Regression
```{r warning=FALSE, message=FALSE}
svr.fit <- train(score ~ .,  data = train,
                 method= "svmLinear2",
                 preProcess = c("center", "scale"),
                 tuneGrid = data.frame(cost = exp(seq(-10,-5,len=20))),
                 trControl = ctrl1) 

ggplot(svr.fit, highlight = TRUE)

```

```{r}
predy.svr <-predict(svr.fit, newdata = test)



mae(test$score, predy.svr)
mse(test$score, predy.svr)
rmse(test$score, predy.svr)

```







##Compare models

```{r}
resamp <-resamples(list(lm = lm.fit, lasso=lasso.fit,rpart = rpart.fit, rf=rf.fit, svr=svr.fit))
summary(resamp)

bwplot((resamp), metric = "RMSE")

bwplot((resamp), metric = "MAE")
```





```{r message=FALSE, warning=FALSE}
```{r message=FALSE, warning=FALSE}
```{r message=FALSE, warning=FALSE}
```{r message=FALSE, warning=FALSE}
```{r message=FALSE, warning=FALSE}
```{r message=FALSE, warning=FALSE}
